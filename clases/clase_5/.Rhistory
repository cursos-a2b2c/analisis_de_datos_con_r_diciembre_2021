vecMin( c(1,2,3), c(2,0,0) )
vecMin( c(1,2,3), c(2,2,0) )
vecMin( c(1,2,3), c(2,3,0) )
vecMin( c(1,2,3), c(2,1,0) )
pmin()
vecMin( c(1,2,3), c(2,0,0) )
pMin( c(1,2,3), c(2,0,0) )
pmin( c(1,2,3), c(2,0,0) )
pmin( c(Inf,2,3), c(2,0,0) )
edgeRUsersGuide()
BiocManager::install("edgeR")
edgeRUsersGuide()
library(edgeR)
edgeRUsersGuide()
agrep("gc", "Gonzalez Catán")
agrep("gonzales katan", "Gonzalez Catán")
agrep("gonzales katan", "Gonzalez Catán", max.distance = 2)
agrep("gonzales katan", "Gonzalez Catán", max.distance = 10)
agrep("gonzales katan", "Gonzalez Catán", max.distance = 0.9)
agrep("gonzales katan", "Gonzalez Catán", max.distance = 0.1)
agrep("gonzales katan", "Gonzalez Catán", max.distance = 0.2)
agrep("gonzales katan", "Gonzalez Catán", max.distance = 0.3)
agrep("gonzales catan", "Gonzalez Catán", max.distance = 0.3)
agrep("gonzales catán", "Gonzalez Catán", max.distance = 0.3)
agrep("gc", "Gonzalez Catán", max.distance = 0.3)
agrep("gc", "Gonzalez Catán", max.distance = 0.5)
agrep("gc", "Gonzalez Catán", max.distance = 0.9)
agrep("gc", "Gonzalez Catán", max.distance = 0.8)
agrep("gc", "Gonzalez Catán", max.distance = 0.7)
agrep("gc", "Gonzalez Catán", max.distance = 0.6)
agrep("gc", "Gonzalez Catán", max.distance = 0.4)
agrep("gc", "Gonzalez Catán", max.distance = 0.5)
agrep("gc", "Gonzalez Catán", max.distance = 0.51)
agrep("gc", "Gonzalez Catán", max.distance = 0.55)
agrep("gc", c("Gonzalez Catán", "Carlos perez"), max.distance = 0.55)
agrep("gc", c("Gonzalez Catán", "Carlos perez"), max.distance = 0.5)
agrep("gc", c("Gonzalez Catán", "Carlos perez"), max.distance = 0.51)
agrep("gonzales katan", c("Gonzalez Catán", "Carlos perez"), max.distance = 0.51)
rbinom
?rbinom
#Las gallinas femeninas son mas valiosas para las granjas que las masculinas porque
#pueden poner huevos. Un laboratorio quiere probar tres drogas que supuestamente aumentan la probabilidad
#de que una gallina nazca femenina en lugar de masculina.
#Aplica cada tipo de droga en tres grupos de 48 gallinas (una droga por grupo) y obtiene los siguientes resultados:
#Droga 1: 25 F 23 M
#Droga 2: 47 F 1 M
#Droga 3: 31 F 17 M
#¿Qué dirían respecto a cada droga?
#Si suponemos que sin la droga, la probabilidad de que sea M o F es 50%, ¿cuál es la probabilidad de obtener
#cada uno de esos resultados por azar?
dbinom(0:48, 48, prob = 0.5)
#Las gallinas femeninas son mas valiosas para las granjas que las masculinas porque
#pueden poner huevos. Un laboratorio quiere probar tres drogas que supuestamente aumentan la probabilidad
#de que una gallina nazca femenina en lugar de masculina.
#Aplica cada tipo de droga en tres grupos de 48 gallinas (una droga por grupo) y obtiene los siguientes resultados:
#Droga 1: 25 F 23 M
#Droga 2: 47 F 1 M
#Droga 3: 31 F 17 M
#¿Qué dirían respecto a cada droga?
#Si suponemos que sin la droga, la probabilidad de que sea M o F es 50%, ¿cuál es la probabilidad de obtener
#cada uno de esos resultados por azar?
sum(dbinom(0:48, 48, prob = 0.5))
#Las gallinas femeninas son mas valiosas para las granjas que las masculinas porque
#pueden poner huevos. Un laboratorio quiere probar tres drogas que supuestamente aumentan la probabilidad
#de que una gallina nazca femenina en lugar de masculina.
#Aplica cada tipo de droga en tres grupos de 48 gallinas (una droga por grupo) y obtiene los siguientes resultados:
#Droga 1: 25 F 23 M
#Droga 2: 47 F 1 M
#Droga 3: 31 F 17 M
#¿Qué dirían respecto a cada droga?
#Si suponemos que sin la droga, la probabilidad de que sea M o F es 50%, ¿cuál es la probabilidad de obtener
#cada uno de esos resultados por azar?
hist(dbinom(0:48, 48, prob = 0.5))
#Las gallinas femeninas son mas valiosas para las granjas que las masculinas porque
#pueden poner huevos. Un laboratorio quiere probar tres drogas que supuestamente aumentan la probabilidad
#de que una gallina nazca femenina en lugar de masculina.
#Aplica cada tipo de droga en tres grupos de 48 gallinas (una droga por grupo) y obtiene los siguientes resultados:
#Droga 1: 25 F 23 M
#Droga 2: 47 F 1 M
#Droga 3: 31 F 17 M
#¿Qué dirían respecto a cada droga?
#Si suponemos que sin la droga, la probabilidad de que sea M o F es 50%, ¿cuál es la probabilidad de obtener
#cada uno de esos resultados por azar?
hist(pbinom(0:48, 48, prob = 0.5))
#Las gallinas femeninas son mas valiosas para las granjas que las masculinas porque
#pueden poner huevos. Un laboratorio quiere probar tres drogas que supuestamente aumentan la probabilidad
#de que una gallina nazca femenina en lugar de masculina.
#Aplica cada tipo de droga en tres grupos de 48 gallinas (una droga por grupo) y obtiene los siguientes resultados:
#Droga 1: 25 F 23 M
#Droga 2: 47 F 1 M
#Droga 3: 31 F 17 M
#¿Qué dirían respecto a cada droga?
#Si suponemos que sin la droga, la probabilidad de que sea M o F es 50%, ¿cuál es la probabilidad de obtener
#cada uno de esos resultados por azar?
plot(0:48, pbinom(0:48, 48, prob = 0.5))
#Las gallinas femeninas son mas valiosas para las granjas que las masculinas porque
#pueden poner huevos. Un laboratorio quiere probar tres drogas que supuestamente aumentan la probabilidad
#de que una gallina nazca femenina en lugar de masculina.
#Aplica cada tipo de droga en tres grupos de 48 gallinas (una droga por grupo) y obtiene los siguientes resultados:
#Droga 1: 25 F 23 M
#Droga 2: 47 F 1 M
#Droga 3: 31 F 17 M
#¿Qué dirían respecto a cada droga?
#Si suponemos que sin la droga, la probabilidad de que sea M o F es 50%, ¿cuál es la probabilidad de obtener
#cada uno de esos resultados por azar?
plot(0:48, dbinom(0:48, 48, prob = 0.5))
#Las gallinas femeninas son mas valiosas para las granjas que las masculinas porque
#pueden poner huevos. Un laboratorio quiere probar tres drogas que supuestamente aumentan la probabilidad
#de que una gallina nazca femenina en lugar de masculina.
#Aplica cada tipo de droga en tres grupos de 48 gallinas (una droga por grupo) y obtiene los siguientes resultados:
#Droga 1: 25 F 23 M
#Droga 2: 47 F 1 M
#Droga 3: 31 F 17 M
#¿Qué dirían respecto a cada droga?
#Si suponemos que sin la droga, la probabilidad de que sea M o F es 50%, ¿cuál es la probabilidad de obtener
#cada uno de esos resultados por azar?
plot(0:48, dbinom(0:48, 48, prob = 0.5),type='h')
#Las gallinas femeninas son mas valiosas para las granjas que las masculinas porque
#pueden poner huevos. Un laboratorio quiere probar tres drogas que supuestamente aumentan la probabilidad
#de que una gallina nazca femenina en lugar de masculina.
#Aplica cada tipo de droga en tres grupos de 48 gallinas (una droga por grupo) y obtiene los siguientes resultados:
#Droga 1: 25 F 23 M
#Droga 2: 47 F 1 M
#Droga 3: 31 F 17 M
#¿Qué dirían respecto a cada droga?
#Si suponemos que sin la droga, la probabilidad de que sea M o F es 50%, ¿cuál es la probabilidad de obtener
#cada uno de esos resultados por azar?
cuantos_masculinos <- 0:48
densidad_de_masculinos <- dbinom(cuantos_masculinos, 48, prob = 0.5)
plot(cuantos_masculinos, densidad_de_masculinos,type='h')
plot(cuantos_masculinos, probabilidad_de_masculinos,type='h')
#Las gallinas femeninas son mas valiosas para las granjas que las masculinas porque
#pueden poner huevos. Un laboratorio quiere probar tres drogas que supuestamente aumentan la probabilidad
#de que una gallina nazca femenina en lugar de masculina.
#Aplica cada tipo de droga en tres grupos de 48 gallinas (una droga por grupo) y obtiene los siguientes resultados:
#Droga 1: 25 F 23 M
#Droga 2: 47 F 1 M
#Droga 3: 31 F 17 M
#¿Qué dirían respecto a cada droga?
#Si suponemos que sin la droga, la probabilidad de que sea M o F es 50%, ¿cuál es la probabilidad de obtener
#cada uno de esos resultados por azar?
cuantos_masculinos         <- 0:48
probabilidad_de_masculinos <- dbinom(cuantos_masculinos, 48, prob = 0.5)
plot(cuantos_masculinos, probabilidad_de_masculinos,type='h')
#Calculemos la probabilidad de obtener 17 o menos "a mano".
sum(dbinom(0:17, 48, prob = 0.5))
sum(dbinom(31:48, 48, prob = 0.5))
#Calculemos la probabilidad de haber obtenido cada una de esas cosas por azar,
binom.test(0:17, 48, p = 0.5, "less")
#Calculemos la probabilidad de haber obtenido cada una de esas cosas por azar,
binom.test(17, 48, p = 0.5, "less")
#Otra hipotesis alternativa podria ser que la droga cambia la probabilidad de 0.5 de obtener F o M, pero sin
#indicar cual tiene mas probabilidad y cual menos. Entonces ademas de probar 17 o menos, deberiamos probar 31 o
#mas.
sum(dbinom(0:17, 48, prob = 0.5)) + sum(dbinom(31:48, 48, prob = 0.5))
#Veamos como hacer este test usando funciones de R en lugar de hacerlo a mano
binom.test(17, 48, p = 0.5, "less")
binom.test(17, 48, p = 0.5, "two.sided")
a <- 3
x <- 2
x <- 2
x <- 2
y <- 10
w <- x + y
w
x == y
a <- x == y
print(a)
a
?class
class(x)
class(a)
class(class)
class(c(x, a))
class(a)
GFP <- 509
GFP <- 509
class(GFP)
class(gfp)
gfp <- 2
gfp
GFP
Gfp
?as.character
as.character(GFP)
GFP
class(GFP)
GFP_character <- as.character(GFP)
class(GFP_character)
verde
GFP <- verde
GFP <- "verde"
GFP
?as.numeric
as.numeric(GFP)
b <- as.numeric(GFP)
b
class(b)
NA == NA
NA + 2
?c
c(1, 2, 3)
c(1, 2, 3, x)
c(1, 2, y, 3, x)
r1 <- c(1, 2, y, 3, x, 35, 46, 76, 7, 10)
r1[1]
r1[6]
runif(10, 0, 100)
sample(0:100, 10)
0:100
class(0:100)
(0:100)[53]
source('~/.active-rstudio-document', echo=TRUE)
v_0_100 <- 0:100
v_0_100
class(c("verde", "rojo", "azul"))
sample(c("verde", "rojo", "azul"), 1)
sample(c("verde", "rojo", "azul"), 1)
sample(c("verde", "rojo", "azul"), 2)
sample(c("verde", "rojo", "azul"), 3)
sample(c("verde", "rojo", "azul"), 10, replace = T)
sample(c("verde", "rojo", "azul"), 10)
sample(c("verde", "rojo", "azul"), 10, replace = F)
sample(c("verde", "rojo", "azul"), 10, replace = T)
?runif
runif(10)
runif(10, mix = 10)
runif(10, max = 10)
?sample
r1
r2
r2 <- sample(0:100, 10)
r2
r1 + r2
c(r1, r2, r1, r1, r2)
c(r1, r2)
r1*r2
class(r2)
class(1)
class(0:0)
0:0
class(0:0)
class(0)
1.3
1/3
class(1/3)
r3 <- c(1.2, 3, 5.3)
3/1
class(r1+r2)
as.numeric("10")
as.numeric("10A")
install.packages("BiocManager")
library(BiocManager)
install("DECIPHER")
?install.packages
?update.packages
install("Biostrings")
install.packages("openxlsx")
library(openxlsx)
library(openxlsxs)
#R tiene una funcion que nos devuelve esta probabilidad
dbinom(1, 1, prob = 0.5)
#R tiene una funcion que nos devuelve esta probabilidad
dbinom(x = 1, size = 1, prob = 0.5)
dbinom(x = 1, size = 2, prob = 0.5)
dbinom(x = 2, size = 2, prob = 0.5)
dbinom(x = 1, size = 10, prob = 0.5)
dbinom(x = 1, size = 10, prob = 0.1)
dbinom(x = 1, size = 10, prob = 0.2)
dbinom(x = 1, size = 10, prob = 0.5)
dbinom(x = 1, size = 10, prob = 0.1)
install.packages("openxlsx")
oxford_mindfulness <- read.csv("~/cursos/analisis_de_datos_con_r_diciembre_2021/clases/clase_2/oxford_mindfulness.csv")
View(oxford_mindfulness)
oxford_mindfulness <- read.csv("~/cursos/analisis_de_datos_con_r_diciembre_2021/clases/clase_2/oxford_mindfulness.csv")
?is.na
is.na(oxford_mindfulness)
which(is.na(oxford_mindfulness), arr.ind = T)
nrow(oxford_mindfulness)
complete.cases(oxford_mindfulness)
a <- c(TRUE, FALSE, TRUE, TRUE, FALSE)
a
which(a)
class(oxford_mindfulness)
class(is.na(oxford_mindfulness))
which(is.na(oxford_mindfulness))
which(is.na(oxford_mindfulness)), arr.ind = T)
which(is.na(oxford_mindfulness), arr.ind = T)
complete.cases(oxford_mindfulness)
oxford_mindfulness[1, ]
oxford_mindfulness[1, ]
oxford_mindfulness[1:5, ]
oxford_mindfulness[c(1, 3, 5), ]
oxford_mindfulness[c(1, 3, 5, 160), ]
which(a)
casos <- complete.cases(oxford_mindfulness)
casos
which(casos)
icasos <- which(casos)
oxford_mindfulness[icasos, ]
casos
!casos
which(!casos)
casos
oxford_mindfulness[casos, ]
oxford_mindfulness_sin_datos_faltantes <- oxford_mindfulness[casos, ]
?duplicated
duplicated(oxford_mindfulness_sin_datos_faltantes)
which(duplicated(oxford_mindfulness_sin_datos_faltantes))
table(duplicated(oxford_mindfulness_sin_datos_faltantes))
table(casos)
head(oxford_mindfulness_sin_datos_faltantes)
class(oxford_mindfulness_sin_datos_faltantes$Depression_T3)
head(oxford_mindfulness_sin_datos_faltantes$Depression_T3)
depre_t3 <- oxford_mindfulness_sin_datos_faltantes$Depression_T3
depre_t1 <- oxford_mindfulness_sin_datos_faltantes$Depression_T1
head(depre_t1)
head(depre_t3 - depre_t1)
depre_t3t1 <- depre_t3 - depre_t1
colnames(oxford_mindfulness_sin_datos_faltantes)
oxford_mindfulness_sin_datos_faltantes$Depression_T3T1
oxford_mindfulness_sin_datos_faltantes$Depression_T3T1 <- depre_t3t1
colnames(oxford_mindfulness_sin_datos_faltantes)
head(oxford_mindfulness_sin_datos_faltantes)
oxford_mindfulness_sin_datos_faltantes[, "a"] <- depre_t3t1
colnames(oxford_mindfulness_sin_datos_faltantes)
?write.table
write.table(oxford_mindfulness_sin_datos_faltantes, file="cursos/analisis_de_datos_con_r_diciembre_2021/clases/clase_3/oxford.csv", quote = F, sep = ",", row.names = F)
setwd("~/cursos/analisis_de_datos_con_r_diciembre_2021/clases/clase_5")
#Veamos otro dataset. Pokemon
#write.csv(Pokemon[, c("Name", "HP", "Attack", "Defense", "Sp..Atk", "Sp..Def", "Speed")], file="pokemon.csv", row.names = F)
pokemon <- read.csv("pokemon.csv")
View(pokemon)
#Nos quedamos con los nombres y los sacamos del dataset
nombres <- pokemon$Name
pokemon <- pokemon[, -1]
#Grafiquemos a los pokemon. 6 variable, cómo hacemos?
#PCA al rescate
pokemon.pca <- prcomp(pokemon, center = T, scale. = T) #Centramos y escalamos para que todas las variables esten en la misma escala y dimension
plot(pokemon.pca$sdev/sum(pokemon.pca$sdev)*100, xlab = "# variable", ylab = "Porcentaje de variabilidad explicada", type = "b")
#Como explicamos alrededor de un 50% de la variabilidad con las primeras dos componentes
#no va a ser tan buena la proyeccion de como se ven nuestros datos pero es lo que tenemos
#Graficamos PCA
plot(pokemon.pca$x[, 1:2], main = "Pokemon")
#Calculemos la distancia entre cada uno y veamos si podemos ordenarlos en un arbol
pokemon_escaleado <- as.data.frame(scale(pokemon, center = T, scale = T)) #Recuerden escalear!
?dist
distancia    <- dist(pokemon_escaleado, method = "euclidean")
?hclust
dendrograma  <- hclust(distancia, method = "complete")
plot(dendrograma, labels = nombres[dendrograma$order])
plot(dendrograma, labels = dendrograma$labels)
plot(dendrograma, labels = nombres[dendrograma$labels])
plot(dendrograma, labels = nombres[dendrograma$order])
#Sacamos los labels
plot(dendrograma, hang = -1, labels = F)
#Como encontramos los clusters? Hay que cortar en algún lado!
abline(h = 6.5, col = "red")
clusters <- cutree(dendrograma, h = 6.5)
clusters
table(clusters)
nombres[clusters == 4] #Qué tipo de grupo es?
nombres[clusters == 4] #Qué tipo de grupo es?
nombres[clusters == 1] #Y este?
table(clusters)
nombres[clusters == 4] #Qué tipo de grupo es?
#Se usa asi, solo a modo de ejemplo, no se preocupen
pvalue <- phyper(cantidad_de_mega_en_cluster_4-1, cantidad_total_de_mega, cantidad_total_de_pokemon - cantidad_total_de_mega, cantidad_en_cluster_4, lower.tail = F)
#.
#.
#.
#.
#Veamos si hay más mega en el cluster 4 que lo que cabria esperar por azar. Usamos un test de hipotesis hipergeometrico, tambien llamado de sobrerepresentacion
cantidad_total_de_pokemon     <- 800
cantidad_total_de_mega        <- 49 #Los habia contado antes
cantidad_en_cluster_4         <- 59
cantidad_de_mega_en_cluster_4 <- 22 #Tambien ya los habia contado antes
#Se usa asi, solo a modo de ejemplo, no se preocupen
pvalue <- phyper(cantidad_de_mega_en_cluster_4-1, cantidad_total_de_mega, cantidad_total_de_pokemon - cantidad_total_de_mega, cantidad_en_cluster_4, lower.tail = F)
pvalue #Rechazamos la hipotesis de que podriamos haber obtenido esto por azar, claramente este cluster es de megas
#Estamos en distintas escalas, podemos iterar
pokemon_normales <- pokemon_escaleado[clusters == 1, ]
nombres_normales <- nombres[clusters == 1]
distancia    <- dist(pokemon_normales, method = "euclidean")
dendrograma  <- hclust(distancia, method = "complete")
plot(dendrograma, labels = F, hang = -1)
#Cortamos
abline(h = 3.8, col = "red")
clusters_normales <- cutree(dendrograma, h = 3.8)
table(clusters_normales)
#Vemos que hay
nombres_normales[clusters_normales == 6]
nombres_normales[clusters_normales == 1]
#Exploremos el dataset
View(trees)
head(trees)
nrow(trees)
plot(trees$Girth, trees$Volume, xlab = "diametro", ylab = "volumen", main = "Cerezos")
#R permite ajustar un modelo lineal a los datos usando un objeto de tipo "formula", que es una forma facil
#de especificar la relacion entre variables
formula_para_ajuste <- Volume ~ Girth
formula_para_ajuste
class(formula_para_ajuste)
#Podemos hacer que dependa de todas las variables que querramos
Volume ~ Girth + Height
#E incluso usar interacción
Volume ~ Girth + Height + Girth:Height
#Ajustemos un modelo lineal
ajuste <- lm(formula = formula_para_ajuste, data = trees)
#Veamos qué devuelve el ajuste? Que es cada cosa? Que significan?
summary(ajuste)
#La interpretacion fisica o biologica se la tenemos que dar nosotros, no viene de los datos
#Grafiquemos todo junto
abline(ajuste, col="red")
#Ademas de modelar una relacion, podemos usar este modelo para encontrar el volumen de un arbol solamente midiendo su diametro
#Medimos el diametro de un nuevo árbol, que volumen esperamos que tenga?
nuevo_arbol <- data.frame(Girth = 13.7)
volumen <- predict.lm(ajuste, nuevo_arbol)
volumen
points(nuevo_arbol$Girth[1], volumen, col="blue", pch=19)
#Esta prediccion es buena? Como podriamos saberlo si no medimos el volumen?
#Podemos usar los valores conocidos y compararlos con como los predice mi modelo
fitted(ajuste)
#Y con esto calcular el error cuadratico medio de mi prediccion
mean((trees$Volume-fitted(ajuste))^2)
#Y si en lugar de usar una funcion lineal, usaramos un polinomio de grado 17?
ajuste_polinomial <- lm(Volume ~ poly(Girth,17), trees)
#Y si en lugar de usar una funcion lineal, usaramos un polinomio de grado 17?
ajuste_polinomial <- lm(Volume ~ poly(Girth,17), trees)
mean((trees$Volume-fitted(ajuste_polinomial))^2)
#Bastante menos, pero esta bueno? por que?
lines(trees$Girth, fitted(ajuste_polinomial), col = "green")
volumen <- predict.lm(ajuste_polinomial, nuevo_arbol)
points(nuevo_arbol$Girth[1], volumen, col="violet", pch=19)
#Se ajusta demasiado a nuestros puntos, no nos permite generalizar a nuevos datos, estamos sobreajustando!
#Querer saber como se comporta nuestro modelo usando los mismos datos con los que lo "entrenamos" es mordernos la cola.
#Una solucion es separar un conjunto de datos de validacion, un 20% de los datos, por ejemplo, y "entrenar" nuestro modelo con el 80%
#restante.
id_datos_de_validacion <- c(3, 7, 10, 15, 19, 26)
datos_de_entrenamiento <- trees[-id_datos_de_validacion, ]
datos_de_validacion    <- trees[id_datos_de_validacion, ]
#Ajustemos un modelo lineal
ajuste_con_subconjunto <- lm(formula = formula_para_ajuste, data = datos_de_entrenamiento)
abline(ajuste_con_subconjunto, col = "brown")
abline(ajuste_con_subconjunto, col = "brown")
#Ajustemos un modelo lineal
ajuste_con_subconjunto <- lm(formula = formula_para_ajuste, data = datos_de_entrenamiento)
#Veamos como cambiaron las cosas
summary(ajuste)
summary(ajuste_con_subconjunto)
prediccion_volumen_validacion <- predict.lm(ajuste, datos_de_validacion)
mean((datos_de_validacion$Volume-prediccion_volumen_validacion)^2)
mean((trees$Volume-fitted(ajuste))^2) #Comparado con el anterior
library(edgeR)
Raw_counts_data_Analysis4_daf2chd7_vs_daf2 <- read.csv("~/cursos/analisis_de_datos_con_r_diciembre_2021/clases/clase_6/Raw_counts_data_Analysis4_daf2chd7_vs_daf2.csv")
View(Raw_counts_data_Analysis4_daf2chd7_vs_daf2)
library(edgeR)
condiciones <- rep(1:2, each = 5)
condiciones
condiciones <- as.factor(rep(1:2, each = 5))
condiciones
y <- DGEList(counts=Raw_counts_data_Analysis4_daf2chd7_vs_daf2[,2:11],
group = condiciones, genes = Raw_counts_data_Analysis4_daf2chd7_vs_daf2[,1])
y
browseVignettes("edgeR")
edgeRUsersGuide()
edgeRUsersGuide()
y <- calcNormFactors(y, method="TMM")
y
plotMDS(y, col = condiciones)
plotMDS(y, col = rep(1:2, each = 5))
keep <- filterByExpr(y, min.count = 10)
table(keep)
keep <- filterByExpr(y, min.count = 10)
?filterByExpr
y    <- y[keep, ,keep.lib.sizes=FALSE]
class(y)
y
y    <- calcNormFactors(y, method="TMM")
plotMDS(y, col = rep(1:2, each = 5))
#Para fitear una binomial negativa se necesita estimar el parámetro de dispersión de la binomial negativa (1/r, con r
#la cantidad de veces que tiene que fallar la binomial negativa).
y <- estimateDisp(y)
condiciones
design <- model.matrix(~tiempo, data=data.frame(condicion = condiciones, n = colnames(y$counts))
design <- model.matrix(~condicion, data=data.frame(condicion = condiciones, n = colnames(y$counts)))
design
design <- model.matrix(~condicion, data=data.frame(condicion = condiciones))
design
colnames(design) <- colnames(y$counts)
rownames(design) <- colnames(y$counts)
design
y      <- estimateDisp(y, design)
fit    <- glmFit(y, design)
ds     <- glmLRT(fit)
head(ds$coefficients)
head(ds$table$logFC)
#y = a + bx
qvalues <- p.adjust(ds$table$PValue, method = "fdr")
?p.adjust
table(qvalues < 0.05)
bvalues <- p.adjust(ds$table$PValue, method = "bonferroni")
table(bvalues < 0.05)
table(qvalues < 0.01)
table(qvalues < 0.05 & abs(ds$table$logFC) > log2(1.5))
which(qvalues < 0.05 & abs(ds$table$logFC) > log2(1.5))
rownames(y$counts)[which(qvalues < 0.05 & abs(ds$table$logFC) > log2(1.5))]
y$genes[which(qvalues < 0.05 & abs(ds$table$logFC) > log2(1.5))]
y$genes
head(y$genes)
y$genes$genes[which(qvalues < 0.05 & abs(ds$table$logFC) > log2(1.5))]
paste0(y$genes$genes[which(qvalues < 0.05 & abs(ds$table$logFC) > log2(1.5))], collapse = ",")
